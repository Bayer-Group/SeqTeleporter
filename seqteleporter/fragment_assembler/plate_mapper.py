import random
import re
import pandas as pd
import json
from itertools import groupby
from os import path, remove
from typing import Optional, List, Union
import math
from datetime import date
from itertools import product
from openpyxl import load_workbook, workbook

from seqteleporter.utils.utils import multi_well_plate_position_generator, find_point_mutations
from seqteleporter.config import PLATE_FORMATS
from seqteleporter.fragment_assembler.fragment_assembler import assemble_fragments


def generate_synthetic_input(mutations: list, wt_seq: str, number_of_variants: int) -> list[list]:
    """
    Generate synthetic input_draft using a list of provided mutations.
    :param mutations:
    :param wt_seq:
    :param number_of_variants:
    :return:
    :example
    sample_mutations = generate_synthetic_input(mutations=MUTATIONS, wt_seq=SEQUENCE, number_of_variants=10)
    """
    variants = []
    for n in range(number_of_variants):
        k = random.randint(1, len(mutations))
        desired_mutations = random.sample(population=mutations, k=k)
        mutation_notations = []
        variant = []
        for position in desired_mutations:
            aa = random.sample(population=position['aa'], k=1)[0]
            mutation_notation = ''.join([wt_seq[position['position'] - 1], str(position['position']), aa])
            mutation_notations.append(mutation_notation)
            variant = sorted(mutation_notations, key=lambda x: int(re.sub('[A-Z]', '', x)))
        variants.append(variant)
    return variants


def load_module_sheet(module_sheet_path: str) -> pd.DataFrame:
    """
    Load module sheet
    :param module_sheet_path:
    :return:
    :example
    module_tbl = load_module_sheet(module_sheet_path)
    module_tbl.set_index('Sequence Name').to_dict('index')
    """
    xl = pd.ExcelFile(module_sheet_path)
    sheets = xl.sheet_names
    module_tbls = []
    for sheet in sheets:
        module_plate = pd.read_excel(module_sheet_path, sheet_name=sheet)
        module_plate['plate'] = [sheet] * module_plate.shape[0]
        module_tbls.append(module_plate)
    module_tbl = pd.concat(module_tbls)
    return module_tbl


def find_fragment_combination_by_mutations(desired_mutations: list, fragment_table: pd.DataFrame) -> list[str]:
    """
    Find fragment combination
    :param desired_mutations:
    :param fragment_table:
    :return:
    :example find_fragment_combination_by_mutations(desired_mutations=sample_mutations[0], fragment_table=module_tbl)
    """

    grouped_module_names = {k: list(v) for k, v in
                            groupby(fragment_table["Sequence Name"], key=lambda x: x.split("_")[0])}

    sel_names = []
    for span, names in grouped_module_names.items():

        sel_name = ""
        span_start = int(span.split("-")[0])
        span_end = int(span.split("-")[1])

        desired_muts_in_span = [mut for mut in desired_mutations if
                                span_start < int(re.sub("[A-Z]", "", mut)) < span_end]
        # if non of the desired mutations lies in the current fragment, select wild type fragment
        if len(desired_muts_in_span) == 0:
            sel_name = [name for name in names if re.search('wild_type', name)][0]
            sel_names.append(sel_name)
            continue
        # if any of the desired mutations lies in the current fragment, find fragment has identical mutations as the
        # desired mutations
        else:
            for name in names:
                muts = name.split("_")[1:]
                if set(muts) == set(desired_muts_in_span):
                    sel_name = name
        # if no fragment with matching mutations are found
        if sel_name == "":
            sel_name = "_".join([span, "NOT_FOUND"])
        sel_names.append(sel_name)

    return sel_names


def make_readme_sheet(desired_variant_muts_list: list[list], desired_variant_names: Optional[list[str]],
                      plate_map_df: pd.DataFrame, plate_format: int, aa_seq: str, backbone_len: int,
                      start_plasmid_id: Optional[str]) -> pd.DataFrame:
    """
    For a plate mapper file, we need to provide user information of:
     - the list of desired mutations we got as inout to generate the mapper file
     - brief introduction of each tab in the file.
     - date of generation
     - generated by: ProseTeleporter
    """
    general_info = {
        "[GENERAL INFO]": "",
        "Date:": date.today(),
        "The IDOT instruction file is generated using:": "ProSeqTeleporter Tool",
        "Destination Plate Format:": f'{plate_format} well',
        "Starting Variant Plasmid ID:": start_plasmid_id if start_plasmid_id else "None",
        "Sequence Size (bp):": len(aa_seq * 3),
        "Backbone Size (bp):": backbone_len,
        "---------------------------": "---------------------------",
        "": ""
    }
    general_info_df = pd.DataFrame.from_dict(general_info, orient='index')

    tab_info = {
        "[TAB INFO]": "",
        'Tab Name':
            'Tab Description',
        "README:":
            "This tab. It contains the introduction of each tab, and other metadata.",
        "source module table:":
            "The tool uses modules in this table to assemble the desired variants.",
        "not feasible variants:":
            "The list of desired variants that can not be assembled using the modules from the source module table.",
        "source_plt_all_target_plt_all:":
            "The mapping of modules from source plate to the desired variants in destination plate.",
        "source_plate_X_target_plate_X:":
            "The mapping of modules from individual source plate to the desired variants in individual destination "
            "plate.",
        "---------------------------": "---------------------------",
        "": ""
    }
    tab_info_df = pd.DataFrame.from_dict(tab_info, orient='index')
    if not desired_variant_names:
        desired_variant_names = ["_".join(muts) for muts in desired_variant_muts_list]
    desired_variants_header_df = pd.DataFrame.from_dict({'[DESIRED VARIANT INFO]': ''}, orient='index')
    desired_variants = {name: '_'.join(muts) for name, muts in zip(desired_variant_names, desired_variant_muts_list)}
    desired_variants_df = pd.DataFrame.from_dict(desired_variants, orient='index'). \
        reset_index(). \
        rename(columns={'index': 'Target Variant Name', 0: 'Mutations'})

    feasible_variants = (
        plate_map_df[['Mutations', 'Module Plasmid Number', 'Target Plate', 'Target Well', 'Target Variant Sequence']]
        .drop_duplicates()
    )
    desired_variants_df = desired_variants_df.merge(feasible_variants, how='left', on='Mutations')
    desired_variants_df = desired_variants_df.T.reset_index().T.reset_index(drop=True).set_index(0)
    assembled_df = pd.concat([general_info_df,
                              tab_info_df,
                              desired_variants_header_df,
                              desired_variants_df],
                             ignore_index=False)

    return assembled_df


def generate_target_variant_sequence(fragment_sheet_path: str, use_frags: list[str], enzyme:str, wt_seq:str,
                                     five_prime_dna: str, three_prime_dna: str) -> str:
    log_dir = path.join(path.dirname(path.dirname(fragment_sheet_path)), 'logs')
    mutant_dna_file_name = re.sub('order_modules','mutant_dna_fragments', path.basename(fragment_sheet_path))
    mutant_dna_file_name = re.sub('xlsx', 'json', mutant_dna_file_name)
    with open(path.join(log_dir, mutant_dna_file_name)) as f:
        mutant_dna_fragments = json.load(f)

    frags_to_be_assembled = [frag for frag in mutant_dna_fragments if frag['name'] in use_frags]
    assembled_frag = assemble_fragments(a_set_of_dna_fragments=frags_to_be_assembled, enzyme=enzyme, wt_seq=wt_seq,
                                         five_prime_dna=five_prime_dna, three_prime_dna=three_prime_dna)
    return assembled_frag.aa



def plate_mapper(desired_variant_muts_list: list[list], desired_variant_names: Optional[list[str]],
                 fragment_sheet_path: str, plate_format: int, aa_seq: str, backbone_len: int, enzyme: str,
                 five_prime_dna: str, three_prime_dna: str, start_plasmid_id: Optional[str], output_dir: str) -> dict:
    """
    Map Source Fragment Plates to Destination Plates
    :param desired_variant_muts_list:
    :param desired_variant_names:
    :param fragment_sheet_path:
    :param plate_format:
    :param start_plasmid_id:
    :param output_dir:
    :return:
    """
    fragment_table = load_module_sheet(fragment_sheet_path)
    fragment_table[['Concentration_ng_per_ul', 'Amount_per_reaction_fmol', 'Total_Required_Volume_ul']] = float('nan')
    # Anja & Sabine:
    # Could we get an automatic number of how often each fragment will be used in total for the desired variants?
    # We need the information to calculate how much volume we have to pipet for the idot.
    fragment_table[['Module_Usage_Count']] = 0
    destination_well_positions = multi_well_plate_position_generator(
        row_range=PLATE_FORMATS[plate_format]['rows'],
        columns_range=PLATE_FORMATS[plate_format]['columns']
    )
    start_plasmid_num = int(re.sub('[A-Za-z]+', '', start_plasmid_id)) if start_plasmid_id else 0
    plasmid_prefix = re.sub('\\d', '', start_plasmid_id) if start_plasmid_id else 'default'
    fragment_dict = fragment_table.set_index('Sequence Name').to_dict('index')

    plate_map = []
    not_found = {}
    cumulative_variant_count = 0
    found_desired_mutations_idx = []
    for idx, desired_mutations in enumerate(desired_variant_muts_list):
        frag_combi = find_fragment_combination_by_mutations(desired_mutations, fragment_table)
        found_all_frags = all(False if re.search('NOT_FOUND', frag) else True for frag in frag_combi)
        variant_notation = "_".join(desired_mutations)
        if not found_all_frags:
            not_found.update({"_".join(desired_mutations): frag_combi})
            continue
        found_desired_mutations_idx.append(idx)
        cumulative_variant_count += 1
        destination_plate_num = math.ceil(cumulative_variant_count / plate_format)
        destination_well_idx = cumulative_variant_count % plate_format - 1  # from 1-indexing to 0-indexing
        variant_seq = generate_target_variant_sequence(fragment_sheet_path=fragment_sheet_path,
                                                       use_frags=frag_combi, enzyme=enzyme, wt_seq=aa_seq,
                                                       five_prime_dna=five_prime_dna,
                                                       three_prime_dna=three_prime_dna)
        for frag_name in frag_combi:
            fragment_dict[frag_name]['Module_Usage_Count'] += 1
            plate_map.append({
                'Source Plate': fragment_dict[frag_name]['plate'],
                'Target Plate': "".join(['target_plate', str(destination_plate_num)]),
                'Source Well': fragment_dict[frag_name]['Well Position'],
                'Target Well': destination_well_positions[destination_well_idx],
                'Volume_ul': 'PLEASE FILL IN VOLUME',
                'Module': frag_name,
                'Module Plasmid Number': ''.join([plasmid_prefix,
                                                  str(start_plasmid_num + cumulative_variant_count)]),
                'Mutations': variant_notation,
                'Target Variant Sequence': variant_seq
            })
    plate_map_df = pd.DataFrame(plate_map)
    plate_map_not_found_df = pd.DataFrame(not_found).transpose()
    out_file_path = path.join(output_dir, f"{date.today()}_source_destination_plate_map.xlsx")
    fragment_table = pd.DataFrame(fragment_dict).transpose().reset_index().rename(columns={'index': 'Sequence Name'})

    # make README tab
    if desired_variant_names:
        found_desired_variant_names = [desired_variant_names[idx] for idx in found_desired_mutations_idx]
    else:
        found_desired_variant_names = None
    readme_df = make_readme_sheet([desired_variant_muts_list[idx] for idx in found_desired_mutations_idx],
                                  found_desired_variant_names,
                                  plate_map_df, plate_format, aa_seq, backbone_len, start_plasmid_id)
    readme_df = readme_df.reset_index()
    # drop Target Variant Sequence column because this info is already stored in README tab
    plate_map_df = plate_map_df.drop(columns=['Target Variant Sequence'])

    # create an Excel writer object
    with pd.ExcelWriter(out_file_path) as writer:
        # use to_excel function and specify the sheet_name and index
        # to store the dataframe in specified sheet
        readme_df.to_excel(writer, sheet_name="README", index=False, header=False)
        fragment_table.to_excel(writer, sheet_name="source module table", index=False)
        plate_map_df.to_excel(writer, sheet_name="source_plt_all_target_plt_all", index=False)
        plate_map_not_found_df.to_excel(writer, sheet_name="not feasible variants", index=True)

        plate_map_df_gp = plate_map_df.groupby(['Source Plate', 'Target Plate'], as_index=True)
        for idx, df_ in plate_map_df_gp:
            sheet_name = '_'.join([f'source_{idx[0]}', idx[1]])
            df_.sort_values(by='Source Well', axis=0).to_excel(writer, sheet_name=sheet_name, index=False)

        return {'plate_map': plate_map_df, 'not_found': plate_map_not_found_df, 'out_file_path': out_file_path}


def make_variant_mutation_notation_from_fragments(fragment_mut_notations: list[str]) -> str:
    assembled_muts_notation = [re.sub("^.+?_|wild_type", "", muts_notation) for muts_notation in fragment_mut_notations]
    assembled_muts_notation = list(filter(lambda x: x != "", assembled_muts_notation))
    assembled_muts_notation_ls: List = []
    for mut_notation_per_frag in assembled_muts_notation:
        assembled_muts_notation_ls = assembled_muts_notation_ls + mut_notation_per_frag.split('_')
    assembled_muts_notation_ls.sort(key=lambda x: int(x[1:-1]))
    return "_".join(assembled_muts_notation_ls)


def validate_plate_mapping_sheet(plate_mapping_sheet_file: str, desired_variant_muts_list: list[list], wt_seq: str,
                                 desired_variant_names: Optional[list[str]]) -> bool:
    """

    :param plate_mapping_sheet_file:
    :param desired_variant_muts_list:
    :param desired_variant_names:
    :return:
    """
    # import data
    xl = pd.ExcelFile(plate_mapping_sheet_file)
    sheets: List[str] = xl.sheet_names
    plate_mapping_tbls = []
    readme_df = pd.DataFrame()
    for sheet in sheets:
        if re.match('source_plate\\d_target_plate\\d', sheet):
            plate_mapping_tbl = pd.read_excel(plate_mapping_sheet_file, sheet_name=sheet)
            plate_mapping_tbls.append(plate_mapping_tbl)
        if re.match('README', sheet):
            readme_df = pd.read_excel(plate_mapping_sheet_file, sheet_name=sheet)
        if re.match('not feasible variants', sheet):
            not_feasible_variants_df = pd.read_excel(plate_mapping_sheet_file, sheet_name=sheet, index_col=0, header=None)

    if len(plate_mapping_tbls)==0 : raise ValueError("Can not find the mapping sheet tabs!")
    plate_mapping_sheet = pd.concat(plate_mapping_tbls)
    if readme_df.empty: raise ValueError("Can not find the README tab!")
    if readme_df.empty: raise ValueError("Can not find the not feasible variants tab!")

    # validate the assembled variant names in plate_mapping_sheet
    if not desired_variant_names:
        desired_variant_names_ = ["_".join(desired_variant_muts) for desired_variant_muts in desired_variant_muts_list]
    else:
        desired_variant_names_ = desired_variant_names
    validated_plate_mapping_sheet = True
    for desired_variant_muts, desired_variant_name in zip(desired_variant_muts_list, desired_variant_names_):
        desired_variant_muts.sort(key=lambda x: int(x[1:-1]))
        desired_variant_notation = "_".join(desired_variant_muts)
        plate_mapping_per_variant = plate_mapping_sheet[
            plate_mapping_sheet['Mutations'] == '_'.join(desired_variant_muts)]
        if plate_mapping_per_variant.empty:
            if desired_variant_notation not in not_feasible_variants_df.index:
                validated_plate_mapping_sheet = False
                print(f"Validation of desired variant {desired_variant_notation} failed!\n"
                      f"desired_variant_muts={desired_variant_muts}\n"
                      f"desired variant is not feasible using provided modules, "
                      f"but the desired variant iss not listed in the 'not_feasible_variants' tab.")
            continue
        assembled_variant_notation = make_variant_mutation_notation_from_fragments(plate_mapping_per_variant['Module'])
        if '_'.join(desired_variant_muts) != assembled_variant_notation:
            validated_plate_mapping_sheet = False
            print(f"Validation of desired variant {desired_variant_notation} failed!\n"
                  f"desired_variant_muts={desired_variant_muts}\n"
                  f"assembled_variant_notation={assembled_variant_notation}")
    if validated_plate_mapping_sheet:
        print('\nThe plate mapping sheet is validated!')

    # validate the variant names against assembled variant sequence in README sheet
    found = False
    row_idx = None
    for row_idx, value in enumerate(readme_df.iloc[:, 0]):
        if value == '[DESIRED VARIANT INFO]':
            found = True
            break
    if not found: raise ValueError("DESIRED VARIANT INFO is not found in the README tab!")
    variant_info_df = readme_df.drop(range(0, row_idx + 2))
    variant_info_df.columns = readme_df.iloc[row_idx + 1]
    validations = variant_info_df.apply(
        lambda x: x['Mutations'] == '_'.join(find_point_mutations(wt_seq, x['Target Variant Sequence'])), axis=1)
    if all(validations):
        validated_readme = True
        print('\nThe README sheet is validated!')
    else:
        validated_readme = False
        print(f"These mutation names are inconsistent with their sequence! \n"
              f"{variant_info_df[~validations]['Mutations'].values}")

    return (validated_readme and validated_plate_mapping_sheet)


def make_and_validate_plate_mapping_sheet(
        desired_variant_muts_list: list[list],
        desired_variant_names: Optional[list[str]],
        fragment_sheet_path: str,
        plate_format: int,
        aa_seq: str,
        backbone_len: int,
        enzyme: str,
        five_prime_dna: str,
        three_prime_dna: str,
        start_plasmid_id: Optional[str]
) -> None:
    # if encounter error msg: Can't find workbook in OLE2 compound document, remove excel sensitivity label and try again.
    # ref: https://stackoverflow.com/questions/45725645/pandas-unable-to-open-this-excel-file
    output_dir = path.dirname(fragment_sheet_path)

    plate_mapping_res = plate_mapper(
        desired_variant_muts_list=desired_variant_muts_list,
        desired_variant_names=desired_variant_names,
        fragment_sheet_path=fragment_sheet_path,
        plate_format=plate_format,
        aa_seq=aa_seq,
        backbone_len=backbone_len,
        enzyme=enzyme,
        five_prime_dna=five_prime_dna,
        three_prime_dna=three_prime_dna,
        start_plasmid_id=start_plasmid_id,
        output_dir=output_dir
    )
    # validate plate mapping sheet
    if not validate_plate_mapping_sheet(plate_mapping_sheet_file=plate_mapping_res['out_file_path'],
                                        desired_variant_muts_list=desired_variant_muts_list, wt_seq=aa_seq,
                                        desired_variant_names=desired_variant_names):
        remove(plate_mapping_res['out_file_path'])
        raise ValueError('Failed to validate plate mapping sheet')

    # add excel formula to allow automatic volume calculation by users
    batch_add_excel_volume_calc_formula(excel_file_path=plate_mapping_res['out_file_path'])

    print(f"\nPlate mapping sheet is exported to:\n {plate_mapping_res['out_file_path']}")
    print(f"\nPreview of mapping sheet: \n {plate_mapping_res['plate_map'].head(3)}")
    if plate_mapping_res['not_found'].shape[0] > 0:
        print(f"Some desired variants can not be assembled from the fragments in the provided list:\n"
              f"{fragment_sheet_path} \n"
              f"{plate_mapping_res['not_found']}")


def make_desired_variant_list_from_a_list_of_mutations(mutations_1idx: List[dict], s: str,
                                                       positions_include_wt_aa: List[int]) -> List[List[str]]:
    all_muts = []
    for mut in mutations_1idx:
        mut_notations = ["".join([s[mut['position'] - 1], str(mut['position']), aa]) for aa in mut['aa']]
        if mut['position'] in positions_include_wt_aa:
            mut_notations.append('wt')
        all_muts.append(mut_notations)
    probable_variants = [list(set(var) - {'wt'}) for var in product(*all_muts)]

    return probable_variants


def find_column_index_by_column_name(sheet: workbook.workbook.Workbook, column_name: str,
                                     header_row: int) -> Union['str', None]:
    # Initialize a variable to hold the column_index
    column_index = None

    # Iterate through the first row to find the column name
    for cell in sheet[header_row]:  # Assuming the first row contains headers
        if cell.value == column_name:
            cell_coordinate = cell.coordinate  # Get the cell coordinate (e.g., 'A1')
            column_index = re.sub('\\d', '', cell_coordinate)
            break

    return column_index


def add_excel_volume_calc_formula_to_target_sheet(
        source_module_sheet_name: str,
        target_sheet_name: str,
        workbook_: workbook.Workbook,
        dna_size: int
) -> workbook.Workbook:

    # identify the col_index of the Volume cells and Module name from the instruction sheets
    target_sheet = workbook_[target_sheet_name]
    volume_col_index = find_column_index_by_column_name(sheet=target_sheet, column_name='Volume_ul', header_row=1)
    mod_name_col_index = find_column_index_by_column_name(sheet=target_sheet, column_name='Module', header_row=1)

    # identify the col_index of the Sequence Name and Concentration column from the source module table
    source_module_sheet = workbook_[source_module_sheet_name]
    src_conc_col_index = find_column_index_by_column_name(sheet=source_module_sheet,
                                                          column_name='Concentration_ng_per_ul',
                                                          header_row=1)
    src_mod_name_col_index = find_column_index_by_column_name(sheet=source_module_sheet,
                                                              column_name='Sequence Name',
                                                              header_row=1)
    amount_col_index = find_column_index_by_column_name(sheet=source_module_sheet,
                                                        column_name='Amount_per_reaction_fmol',
                                                        header_row=1)

    # write excel formula into the Volume cells in target_sheet
    # Add a formula to sum the values in the 'Values' column
    # Determine the last row with data
    last_row = target_sheet.max_row

    # Use VLOOKUP in Sheet2 to find corresponding names from Sheet1
    # mass of dsDNA (g) = moles of dsDNA (mol) x ((length of dsDNA (bp) x 615.96 g/mol/bp) + 36.04 g/mol)
    # ref: https://nebiocalculator.neb.com/#!/dsdnaamt
    for row in range(2, last_row + 1):  # Adjusting to include the last row
        dna_mol = f"VLOOKUP({mod_name_col_index}{row},'{source_module_sheet_name}'!{src_mod_name_col_index}:{amount_col_index},9,FALSE)"
        dna_mass = f"{dna_mol}*(({dna_size}*615.96)+36.04)"
        dna_conc = f"VLOOKUP({mod_name_col_index}{row},'{source_module_sheet_name}'!{src_mod_name_col_index}:{src_conc_col_index},8,FALSE)"
        target_sheet[f'{volume_col_index}{row}'] = f"=ROUND({dna_mass}/{dna_conc}/1000000,2)"

    return workbook_


def add_excel_volume_calc_formula_to_source_module_sheet(
        source_module_sheet_name: str,
        workbook_: workbook.Workbook
) -> workbook.Workbook:

    # identify the col_index of the Volume cells and Module name from the instruction sheets
    full_mapping_sheet_name = 'source_plt_all_target_plt_all'
    target_sheet = workbook_[full_mapping_sheet_name]
    volume_col_index = find_column_index_by_column_name(sheet=target_sheet, column_name='Volume_ul', header_row=1)
    mod_name_col_index = find_column_index_by_column_name(sheet=target_sheet, column_name='Module', header_row=1)

    # identify the col_index of the Sequence Name and Concentration column from the source module table
    source_module_sheet = workbook_[source_module_sheet_name]

    src_mod_name_col_index = find_column_index_by_column_name(sheet=source_module_sheet,
                                                              column_name='Sequence Name',
                                                              header_row=1)
    src_mod_total_vol_col_index = find_column_index_by_column_name(sheet=source_module_sheet,
                                                        column_name='Total_Required_Volume_ul',
                                                        header_row=1)
    # add excel formula to source module sheet
    # Determine the last row with data
    last_row = source_module_sheet.max_row
    for row in range(2, last_row + 1):  # Adjusting to include the last row
        search_range = f"'{full_mapping_sheet_name}'!{mod_name_col_index}:{mod_name_col_index}"
        criteria = f"'{source_module_sheet_name}'!{src_mod_name_col_index}{row}"
        sum_range = f"'{full_mapping_sheet_name}'!{volume_col_index}:{volume_col_index}"
        source_module_sheet[f'{src_mod_total_vol_col_index}{row}'] = f"=SUMIF({search_range},{criteria},{sum_range})"

    return workbook_


def batch_add_excel_volume_calc_formula(excel_file_path: str) -> None:
    workbook_ = load_workbook(excel_file_path)

    # identify DNA size
    readme_sheet = workbook_['README']
    dna_len = 0
    for row in range(1, readme_sheet.max_row + 1):
        if readme_sheet[f'A{row}'].value and re.search("Sequence Size|Backbone Size", readme_sheet[f'A{row}'].value):
            dna_len += int(readme_sheet[f'B{row}'].value)

    target_sheet_names = [sheet_name for sheet_name in workbook_.sheetnames if
                          re.search('.*source.*target.*', sheet_name)]
    for target_sheet_name in target_sheet_names:
        workbook_ = add_excel_volume_calc_formula_to_target_sheet(source_module_sheet_name='source module table',
                                                                  target_sheet_name=target_sheet_name,
                                                                  workbook_=workbook_,
                                                                  dna_size=dna_len)
    workbook_ = add_excel_volume_calc_formula_to_source_module_sheet(source_module_sheet_name='source module table',
                                                                     workbook_=workbook_)

    # Save the workbook
    workbook_.save(excel_file_path)
