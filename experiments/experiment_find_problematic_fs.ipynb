{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to read the text file and convert it into the desired format.\n",
    "def prepare_dataset(file_path):\n",
    "    # Initialize an empty list to store dictionaries.\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Open the text file for reading.\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line in the file.\n",
    "        for line in file:\n",
    "            # Split the line by ';' to separate the fidelity and the set.\n",
    "            parts = line.split(';')\n",
    "            # Extract the fidelity value, converting it to float.\n",
    "            fidelity = float(parts[0].split(':')[1])\n",
    "            # Evaluate the string representation of the tuple to a tuple and then convert it to a list.\n",
    "            set_values = eval(parts[1])\n",
    "            # Append a new dictionary to the list with the 'set' and 'fidelity' keys.\n",
    "            list_of_dicts.append({'candidate_fs': set(set_values), 'fidelity': fidelity})\n",
    "\n",
    "    return list_of_dicts\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_cleaned = prepare_dataset(file_path=r'C:\\Users\\GOFKV\\PycharmProjects\\cookie_cutter\\output\\logs_exp_incl_bad_fs\\testout.txt')\n",
    "data_cleaned[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the sum of output values and count for each item\n",
    "item_outputs = {}\n",
    "\n",
    "# Loop through the dataset to populate the item_outputs dictionary\n",
    "for dic in data_cleaned:\n",
    "    input_list, output_value = dic['candidate_fs'], dic['fidelity']\n",
    "    for item in combinations(input_list, 2):\n",
    "        if item not in set(item_outputs.keys()):\n",
    "            item_outputs[item] = {'sum': 0, 'count': 0}\n",
    "        item_outputs[item]['sum'] += output_value\n",
    "        item_outputs[item]['count'] += 1\n",
    "\n",
    "# Calculate the average output value for each item and sort\n",
    "item_averages = {item: (data['sum'] / data['count']) for item, data in item_outputs.items()}\n",
    "item_averages = dict(sorted(item_averages.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Find the item with the highest and lowest average output value\n",
    "highest_avg_item = max(item_averages, key=item_averages.get)\n",
    "lowest_avg_item = min(item_averages, key=item_averages.get)\n",
    "\n",
    "# Print the items with the highest and lowest average output value\n",
    "print(f\"Item with highest average output value: {highest_avg_item} (Avg: {item_averages[highest_avg_item]})\")\n",
    "print(f\"Item with lowest average output value: {lowest_avg_item} (Avg: {item_averages[lowest_avg_item]})\")\n",
    "\n",
    "# Additional: To further analyze the relationship, consider using statistical or machine learning methods.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "item_averages"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
